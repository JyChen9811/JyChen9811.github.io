---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am currently a Master candidate in the School of Information Engineering, Guangdong University of Techonology, advised by [Prof. Zhijing Yang](https://ieeexplore.ieee.org/author/38512188800). I also collaborate with [Dr. Yukai Shi](https://scholar.google.com/citations?user=z_tI-X4AAAAJ&hl=en). Before that, I received my B.E. degree and advised by [Prof. Jie Xu](https://scholar.google.com/citations?hl=zh-CN&user=HPUG2jwAAAAJ&view_op=list_works&sortby=pubdate) in the School of Information Engineering, Guangdong University of Techonology. 

Research interest: Human Synthesis, Virutual Try-on, Domain Adaption, Self-Supervised Learning. 

***Never stop looking for collaboration, kindly contact me via email.***


# üî• News
- *2022.10*: üéâüéâ One paper about ***virtual try-on*** got the **major revision** by IEEE TMM.
- *2022.08*: üéâüéâ One paper about ***real world image denosing*** was accpeted by KBS [[pdf](https://www.sciencedirect.com/science/article/pii/S0950705122009224?via%3Dihub)], and the training code was released in [DnSwin](https://github.com/House-Leo/DnSwin), congrats to Hao Li.

# üìù Publications 

#### Image Denoising
- ***DnSwin: Toward Real-World Denoising via Continuous Wavelet Sliding-Transformer*** \
**Hao Li**, Zhijing Yang, Xiaobin Hong, Yukai Shi, Junyang Chen, Jinshan Pan \
Knowledge-Based Systems (KBS), 2022. [[arxiv](https://arxiv.org/abs/2207.13861)] [[pdf](https://www.sciencedirect.com/science/article/pii/S0950705122009224?via%3Dihub)] [[code](https://github.com/House-Leo/DnSwin)]

#### Virtual Try-on
- ***OccluMix: Towards De-Occlusion Virtual Try-on by Semantically-Guided Mixup*** \
Zhijing Yang, Junyang Chen, Yukai Shi, **Hao Li**, Tianshui Chen, Liang Lin \
IEEE Transactions on Multimedia (T-MM), *major revision*, 2022.

#### Challenge Report
- ***NTIRE 2022 challenge on stereo image super-resolution: Methods and results*** \
Longguang Wang, Yulan Guo, **Junyang Chen**, et al. \
CVPR Workshops, 2022. [[pdf](https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Wang_NTIRE_2022_Challenge_on_Stereo_Image_Super-Resolution_Methods_and_Results_CVPRW_2022_paper.html)]

<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**
 -->
# üéñ Honors and Awards
- *2021.9* The First Class Scholarship, GDUT.
- *2022.9* The First Class Scholarship, GDUT.

# üìñ Educations
- *2021.09 - now*, Master, School of Information Engineering, Guangdong University of Technology.
- *2017.09 - 2021.06*, Undergraduate, School of Information Engineering, Guangdong University of Technology.

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->
